# Reflection on Project 3: Image Re-Written

Image manipulation was one of the things I was really looking forward to doing from before this course even started, so I had a lot in my colleciton of things that inspired me. So choosing the thing I wanted to do was the first challenge, leading me to try various different approaches to how I wanted to bring forth the structure of an image in a new and interesting way.

First I tried some things shown in class slides, like converting images or sound to text adn editing them in ways that would break how the image was displayed. This approach proved to be very unpredictable, meaning even if I had an interesting effect, parameter tuning would be blind guesswork, and anything during the process could change the way my project looked. I wanted to make something reproducible and explainable anyways, so I ditched this idea for something else. I guess you could say I couldn't discover anything really with a rule-set or instructions with this method.

Then, I tried another approach to make glitch-art by pixel-sorting the background of my camera feed. I set it up using OpenCV (a built-in library for Processing) to track my head position, and pixel-sort horizontally. Although the head-tracking worked, it was super finnicky and I couldn't even get a nice glitch effect. I considered using a shader to glitch it some more, but it felt like frosting on a bland cake.

My final inspiration struck when I was using my iPhone, and I noticed the new feature that allows you to turn any normal photo into a "spatial" picture, and it would parallax and shift as if it were 3-dimensional. I don't know how they did it, but I wrote down a rough idea of what my methodology would be like, and began to dig into the heart of the concept–the depth map.

Depth maps are something moreso used in shaders, but I didn't want to learn GLSL shaders for this project, since it's almost like another language. Also, rendering the depth map in processing would allow me to create unique effects that interact with the rest of my code in processing, so that's what I did, by making a triangle mesh that would overlay the original image as a texture, creating a strange, blanket-like distortion effect.

I used an open-source machine learning depth map generator that could take any image I want and turn it into a clearly defined depth map. It worked so well, that I even processed a video depth map (which I didn't end up using, as getting the still mesh was hard enough on its own).

My final iteration uses an image from the album 'Submarine' by one of my favorite bands the Marías. This image fits my composition as it depicts them underwater, and my depth rendering algorithm adds another layer of the feeling of being submersed, I think. Overall I'm happy with how it turned out, as it features many of the layers that I wanted to include, such as pixelation (if triangles count), transformation (from image to depth-map to 3D object), averaging (which came from a performance compromise), collage (if you can call combining an image with its depth map a collage). But most importantly, I think my project was able to bring a new way of seeing structure in images we see in everyday life.
